{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80cfbb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device (Apple Silicon GPU)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the absolute path of the current notebook\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Get the project root directory (which is the parent of the 'notebooks' directory)\n",
    "project_root = notebook_path.parent\n",
    "\n",
    "# Add BOTH the project root and the src directory to the Python path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "if str(project_root / 'src') not in sys.path:\n",
    "    sys.path.append(str(project_root / 'src'))\n",
    "\n",
    "# Now, we can import our modules\n",
    "from src.data_handling import DataHandler\n",
    "from src.mlp_model import MLPModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fe1b7f",
   "metadata": {},
   "source": [
    "#### Initialize DataHandler\n",
    "This cell creates an instance of the `DataHandler` class. It will load the dataset, define the feature/target sets, and pre-fit the necessary data processing objects. The test year is set to 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0db5ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataHandler initialized - Using 52 features - Test year: 2020\n"
     ]
    }
   ],
   "source": [
    "dh = DataHandler(test_year=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb35ed",
   "metadata": {},
   "source": [
    "### **Model: MLP with 3 Hidden Layers**\n",
    "\n",
    "#### Initialize MLPModel Handler\n",
    "Here, we create an instance of the `MLPModel` class, explicitly setting `depth=3`. The `model_name` ensures all artifacts for this architecture are saved to unique files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfa76816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPModel initialized with model name mlp_depth3 and depth 3.\n",
      "Optuna study will be stored in  : /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/optuna/mlp_depth3_study.pkl\n",
      "Trained model will be stored in : /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/models/mlp_depth3_model.pth\n",
      "Final preds will be stored in   : /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/preds/mlp_depth3_preds.csv\n"
     ]
    }
   ],
   "source": [
    "mlp_depth3 = MLPModel(dh, model_name='mlp_depth3', depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e2b3c8",
   "metadata": {},
   "source": [
    "#### Run Optuna Hyperparameter Study (Depth=2)\n",
    "This cell runs the Optuna study. For this specific 2-layer architecture, it will find the optimal learning rate, weight decay, batch size, and the number of neurons and dropout rates for both hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2610909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-23 11:00:26,067] A new study created in memory with name: mlp_depth3_study\n",
      "[I 2025-10-23 11:00:47,411] Trial 8 pruned. \n",
      "[I 2025-10-23 11:00:48,551] Trial 4 pruned. \n",
      "[I 2025-10-23 11:00:54,872] Trial 1 pruned. \n",
      "[I 2025-10-23 11:01:05,472] Trial 3 pruned. \n",
      "[I 2025-10-23 11:01:21,704] Trial 0 pruned. \n",
      "[I 2025-10-23 11:01:21,877] Trial 11 pruned. \n",
      "[I 2025-10-23 11:01:35,544] Trial 10 pruned. \n",
      "[I 2025-10-23 11:02:10,253] Trial 15 pruned. \n",
      "[I 2025-10-23 11:02:18,952] Trial 16 pruned. \n",
      "[I 2025-10-23 11:02:20,371] Trial 7 pruned. \n",
      "[I 2025-10-23 11:02:33,103] Trial 19 pruned. \n",
      "[I 2025-10-23 11:02:34,304] Trial 12 finished with value: 1.007140616575877 and parameters: {'learning_rate': 0.017362581240268876, 'weight_decay': 0.0004180354987819877, 'batch_size': 256, 'n_hidden_1': 104, 'dropout_rate_1': 0.4568171221117885, 'n_hidden_2': 64, 'dropout_rate_2': 0.31583124018754427, 'n_hidden_3': 16, 'dropout_rate_3': 0.46728165592256327}. Best is trial 12 with value: 1.007140616575877.\n",
      "[I 2025-10-23 11:02:36,804] Trial 18 pruned. \n",
      "[I 2025-10-23 11:02:45,011] Trial 14 pruned. \n",
      "[I 2025-10-23 11:02:48,993] Trial 22 pruned. \n",
      "[I 2025-10-23 11:03:01,817] Trial 24 pruned. \n",
      "[I 2025-10-23 11:03:04,226] Trial 17 pruned. \n",
      "[I 2025-10-23 11:03:13,465] Trial 2 pruned. \n",
      "[I 2025-10-23 11:03:15,570] Trial 21 pruned. \n",
      "[I 2025-10-23 11:03:27,538] Trial 28 pruned. \n",
      "[I 2025-10-23 11:03:53,094] Trial 27 pruned. \n",
      "[I 2025-10-23 11:03:58,271] Trial 20 pruned. \n",
      "[I 2025-10-23 11:04:18,901] Trial 23 finished with value: 1.0030549830860562 and parameters: {'learning_rate': 0.012201814582543574, 'weight_decay': 0.0014626149896585661, 'batch_size': 256, 'n_hidden_1': 128, 'dropout_rate_1': 0.3983645596864108, 'n_hidden_2': 40, 'dropout_rate_2': 0.015616647777166981, 'n_hidden_3': 8, 'dropout_rate_3': 0.23747558311089634}. Best is trial 23 with value: 1.0030549830860562.\n",
      "[I 2025-10-23 11:04:21,992] Trial 25 pruned. \n",
      "[I 2025-10-23 11:04:33,539] Trial 9 finished with value: 1.0008952518304188 and parameters: {'learning_rate': 0.0027766074861463137, 'weight_decay': 0.0040962247909642245, 'batch_size': 192, 'n_hidden_1': 128, 'dropout_rate_1': 0.16131842201159413, 'n_hidden_2': 80, 'dropout_rate_2': 0.053276996805187105, 'n_hidden_3': 120, 'dropout_rate_3': 0.2279617491753682}. Best is trial 9 with value: 1.0008952518304188.\n",
      "[I 2025-10-23 11:04:40,708] Trial 6 pruned. \n",
      "[I 2025-10-23 11:04:43,527] Trial 13 pruned. \n",
      "[I 2025-10-23 11:04:48,003] Trial 26 finished with value: 1.0032953023910522 and parameters: {'learning_rate': 0.006735266199458775, 'weight_decay': 7.530964298926724e-05, 'batch_size': 256, 'n_hidden_1': 112, 'dropout_rate_1': 0.297226305282117, 'n_hidden_2': 40, 'dropout_rate_2': 0.10088282810496152, 'n_hidden_3': 8, 'dropout_rate_3': 0.2270544852128237}. Best is trial 9 with value: 1.0008952518304188.\n",
      "[I 2025-10-23 11:05:01,889] Trial 29 finished with value: 1.0034969713952806 and parameters: {'learning_rate': 0.0073329115345641535, 'weight_decay': 3.1033738682030404e-06, 'batch_size': 256, 'n_hidden_1': 104, 'dropout_rate_1': 0.4367128864735795, 'n_hidden_2': 40, 'dropout_rate_2': 0.13879792219884565, 'n_hidden_3': 16, 'dropout_rate_3': 0.23088247187348757}. Best is trial 9 with value: 1.0008952518304188.\n",
      "[I 2025-10-23 11:05:26,144] Trial 30 finished with value: 1.0026190016004775 and parameters: {'learning_rate': 0.007017951738469157, 'weight_decay': 0.00012209709051370582, 'batch_size': 256, 'n_hidden_1': 112, 'dropout_rate_1': 0.4243493048025101, 'n_hidden_2': 40, 'dropout_rate_2': 0.07881231969560365, 'n_hidden_3': 16, 'dropout_rate_3': 0.22831853823487075}. Best is trial 9 with value: 1.0008952518304188.\n",
      "[I 2025-10-23 11:05:32,276] Trial 31 finished with value: 1.0032592945628696 and parameters: {'learning_rate': 0.006638999878149929, 'weight_decay': 0.00016223115996717507, 'batch_size': 256, 'n_hidden_1': 104, 'dropout_rate_1': 0.4376075110887668, 'n_hidden_2': 40, 'dropout_rate_2': 0.055589684695108374, 'n_hidden_3': 16, 'dropout_rate_3': 0.23055244537594186}. Best is trial 9 with value: 1.0008952518304188.\n",
      "[I 2025-10-23 11:05:53,609] Trial 32 finished with value: 1.003113004896376 and parameters: {'learning_rate': 0.006377792541284916, 'weight_decay': 0.00019596677694436814, 'batch_size': 256, 'n_hidden_1': 104, 'dropout_rate_1': 0.4280792782557526, 'n_hidden_2': 40, 'dropout_rate_2': 0.04440245725490196, 'n_hidden_3': 16, 'dropout_rate_3': 0.2382474455677058}. Best is trial 9 with value: 1.0008952518304188.\n",
      "[I 2025-10-23 11:06:02,758] Trial 33 finished with value: 1.0014876458379958 and parameters: {'learning_rate': 0.006443865229278844, 'weight_decay': 0.00023184145856803843, 'batch_size': 256, 'n_hidden_1': 104, 'dropout_rate_1': 0.21770230944009816, 'n_hidden_2': 32, 'dropout_rate_2': 0.1509548241398379, 'n_hidden_3': 24, 'dropout_rate_3': 0.14157900827472314}. Best is trial 9 with value: 1.0008952518304188.\n",
      "[I 2025-10-23 11:07:07,435] Trial 37 finished with value: 1.0013314286867778 and parameters: {'learning_rate': 0.006158060944644929, 'weight_decay': 0.0028708044265714546, 'batch_size': 192, 'n_hidden_1': 120, 'dropout_rate_1': 0.21378045574128504, 'n_hidden_2': 32, 'dropout_rate_2': 0.05264643786425186, 'n_hidden_3': 32, 'dropout_rate_3': 0.14286453537767219}. Best is trial 9 with value: 1.0008952518304188.\n",
      "[I 2025-10-23 11:07:10,153] Trial 38 finished with value: 1.0013921409845352 and parameters: {'learning_rate': 0.0053944650951309545, 'weight_decay': 0.0028442036036566967, 'batch_size': 192, 'n_hidden_1': 120, 'dropout_rate_1': 0.214732117513621, 'n_hidden_2': 128, 'dropout_rate_2': 0.05057815045679436, 'n_hidden_3': 24, 'dropout_rate_3': 0.14727895093248225}. Best is trial 9 with value: 1.0008952518304188.\n",
      "[I 2025-10-23 11:07:24,189] Trial 34 finished with value: 1.001508308781518 and parameters: {'learning_rate': 0.006320054508474383, 'weight_decay': 0.002099587238629374, 'batch_size': 256, 'n_hidden_1': 112, 'dropout_rate_1': 0.20770770599404462, 'n_hidden_2': 96, 'dropout_rate_2': 0.051526081588891236, 'n_hidden_3': 24, 'dropout_rate_3': 0.15906625441733818}. Best is trial 9 with value: 1.0008952518304188.\n",
      "[I 2025-10-23 11:07:28,943] Trial 39 finished with value: 1.002382720510165 and parameters: {'learning_rate': 0.004926213926114535, 'weight_decay': 0.003045798695461313, 'batch_size': 192, 'n_hidden_1': 72, 'dropout_rate_1': 0.22347094786952393, 'n_hidden_2': 32, 'dropout_rate_2': 0.04664856639880038, 'n_hidden_3': 24, 'dropout_rate_3': 0.14384127017055773}. Best is trial 9 with value: 1.0008952518304188.\n",
      "[I 2025-10-23 11:07:33,791] Trial 36 finished with value: 1.0019995073477428 and parameters: {'learning_rate': 0.008221379870680053, 'weight_decay': 0.0026772267760487357, 'batch_size': 192, 'n_hidden_1': 120, 'dropout_rate_1': 0.23029265772626123, 'n_hidden_2': 96, 'dropout_rate_2': 0.04392703041142945, 'n_hidden_3': 24, 'dropout_rate_3': 0.1028874601209846}. Best is trial 9 with value: 1.0008952518304188.\n",
      "[I 2025-10-23 11:07:33,818] Trial 41 pruned. \n",
      "[I 2025-10-23 11:07:36,042] Trial 40 finished with value: 1.0016521612803142 and parameters: {'learning_rate': 0.005160494653816064, 'weight_decay': 0.0023378305339844785, 'batch_size': 192, 'n_hidden_1': 120, 'dropout_rate_1': 0.21614546997561407, 'n_hidden_2': 32, 'dropout_rate_2': 0.05139245661609752, 'n_hidden_3': 24, 'dropout_rate_3': 0.14759510873351722}. Best is trial 9 with value: 1.0008952518304188.\n",
      "[I 2025-10-23 11:07:44,370] Trial 46 pruned. \n",
      "[I 2025-10-23 11:07:49,312] Trial 48 pruned. \n",
      "[I 2025-10-23 11:07:51,741] Trial 45 pruned. \n",
      "[I 2025-10-23 11:07:53,221] Trial 47 pruned. \n",
      "[I 2025-10-23 11:07:58,019] Trial 49 pruned. \n",
      "[I 2025-10-23 11:08:01,256] Trial 5 finished with value: 1.0005678335825603 and parameters: {'learning_rate': 0.006893765839887174, 'weight_decay': 0.0003526696873415923, 'batch_size': 256, 'n_hidden_1': 56, 'dropout_rate_1': 0.0954602912874219, 'n_hidden_2': 96, 'dropout_rate_2': 0.032160950239147834, 'n_hidden_3': 56, 'dropout_rate_3': 0.24526333680741458}. Best is trial 5 with value: 1.0005678335825603.\n",
      "[I 2025-10-23 11:08:05,518] Trial 42 finished with value: 1.0029608656962712 and parameters: {'learning_rate': 0.00429629429909126, 'weight_decay': 0.0023214105743938718, 'batch_size': 192, 'n_hidden_1': 120, 'dropout_rate_1': 0.2123531736974112, 'n_hidden_2': 16, 'dropout_rate_2': 0.16040177647884202, 'n_hidden_3': 32, 'dropout_rate_3': 0.1515428327708389}. Best is trial 5 with value: 1.0005678335825603.\n",
      "[I 2025-10-23 11:08:22,960] Trial 35 finished with value: 1.0023630609114964 and parameters: {'learning_rate': 0.004992345914186145, 'weight_decay': 0.002637148171046516, 'batch_size': 192, 'n_hidden_1': 120, 'dropout_rate_1': 0.21811897423121462, 'n_hidden_2': 96, 'dropout_rate_2': 0.1587862937234678, 'n_hidden_3': 16, 'dropout_rate_3': 0.12712755999829412}. Best is trial 5 with value: 1.0005678335825603.\n",
      "[I 2025-10-23 11:08:24,524] Trial 43 pruned. \n",
      "[I 2025-10-23 11:08:26,391] Trial 44 finished with value: 1.0026002377271652 and parameters: {'learning_rate': 0.003925857958867116, 'weight_decay': 0.009669201298628544, 'batch_size': 192, 'n_hidden_1': 48, 'dropout_rate_1': 0.2210617573485814, 'n_hidden_2': 120, 'dropout_rate_2': 0.17148683387175231, 'n_hidden_3': 32, 'dropout_rate_3': 0.13517093845758305}. Best is trial 5 with value: 1.0005678335825603.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Study concluded and saved to /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/optuna/mlp_depth3_study.pkl.\n",
      "Best trial: 5\n",
      "Best loss: 1.0005678335825603\n",
      "Best params: {'learning_rate': 0.006893765839887174, 'weight_decay': 0.0003526696873415923, 'batch_size': 256, 'n_hidden_1': 56, 'dropout_rate_1': 0.0954602912874219, 'n_hidden_2': 96, 'dropout_rate_2': 0.032160950239147834, 'n_hidden_3': 56, 'dropout_rate_3': 0.24526333680741458}\n",
      "Best epoch: 26\n"
     ]
    }
   ],
   "source": [
    "mlp_depth3.run_optuna_study(\n",
    "    n_trials=50,\n",
    "    timeout=30,               # Stop study after 30 minutes\n",
    "    max_epochs=40,            # Max epochs to train each trial\n",
    "    min_resource=4,          # Min epochs before pruning\n",
    "    reduction_factor=2,\n",
    "    use_pca=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b08b7c",
   "metadata": {},
   "source": [
    "#### Train Final Model (Depth=3)\n",
    "Using the best hyperparameters and the optimal number of training epochs found by Optuna, this cell trains the final 3-layer MLP on the entire training dataset. The model's weights (`.pth` file) are saved to the results directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "069ee3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mlp_depth3 with depth 3 for 26 epochs with patience of 10 epochs.\n",
      "Using batch size: 256 and best params: {'learning_rate': 0.006893765839887174, 'weight_decay': 0.0003526696873415923, 'batch_size': 256, 'n_hidden_1': 56, 'dropout_rate_1': 0.0954602912874219, 'n_hidden_2': 96, 'dropout_rate_2': 0.032160950239147834, 'n_hidden_3': 56, 'dropout_rate_3': 0.24526333680741458}.\n",
      "Epoch    0, Loss: 1.055174\n",
      "Epoch    1, Loss: 1.005213\n",
      "Epoch    2, Loss: 1.002300\n",
      "Epoch    3, Loss: 0.999997\n",
      "Epoch    4, Loss: 0.999820\n",
      "Epoch    5, Loss: 0.997259\n",
      "Epoch    6, Loss: 0.997366\n",
      "Epoch    7, Loss: 0.997006\n",
      "Epoch    8, Loss: 0.997374\n",
      "Epoch    9, Loss: 0.995933\n",
      "Epoch   10, Loss: 0.994634\n",
      "Epoch   11, Loss: 0.996028\n",
      "Epoch   12, Loss: 0.996111\n",
      "Epoch   13, Loss: 0.993766\n",
      "Epoch   14, Loss: 0.995062\n",
      "Epoch   15, Loss: 0.993454\n",
      "Epoch   16, Loss: 0.994629\n",
      "Epoch   17, Loss: 0.995063\n",
      "Epoch   18, Loss: 0.994409\n",
      "Epoch   19, Loss: 0.993791\n",
      "Epoch   20, Loss: 0.993231\n",
      "Epoch   21, Loss: 0.993995\n",
      "Epoch   22, Loss: 0.994297\n",
      "Epoch   23, Loss: 0.992200\n",
      "Epoch   24, Loss: 0.993434\n",
      "Epoch   25, Loss: 0.993284\n",
      "Training completed in 4.70 seconds.\n",
      "Model saved to /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/models/mlp_depth3_model.pth\n"
     ]
    }
   ],
   "source": [
    "mlp_depth3.train_final_model(patience=10) # Stop if loss doesn't improve for 10 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2443ab8",
   "metadata": {},
   "source": [
    "#### Generate Final Predictions (Depth=3)\n",
    "Finally, we load the trained 3-layer model and use it to make predictions on the held-out 2020 test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03b7bd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_depth3 predictions saved to: /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/preds/mlp_depth3_preds.csv.\n",
      "\n",
      "MLP (Depth=3) Predictions (first 5 rows):\n",
      "[[0.1417415  0.28043145 0.02995418 0.5478728 ]\n",
      " [0.14857827 0.29302874 0.03943167 0.51896125]\n",
      " [0.17976786 0.21175139 0.01185497 0.5966258 ]\n",
      " [0.10410244 0.27115166 0.01873205 0.6060139 ]\n",
      " [0.10320204 0.27827454 0.02192812 0.5965952 ]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the 2020 test data\n",
    "preds_depth3 = mlp_depth3.make_final_predictions()\n",
    "print(\"\\nMLP (Depth=3) Predictions (first 5 rows):\")\n",
    "print(preds_depth3[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math392",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
