{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c94a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the absolute path of the current notebook\n",
    "# Assumes the notebook is in a subdirectory of the project root (e.g., /notebooks)\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Get the project root directory (which is the parent of the 'notebooks' directory)\n",
    "project_root = notebook_path.parent\n",
    "\n",
    "# Add BOTH the project root and the src directory to the Python path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "if str(project_root / 'src') not in sys.path:\n",
    "    sys.path.append(str(project_root / 'src'))\n",
    "\n",
    "# Now, we can import our modules\n",
    "from src.data_handling import DataHandler\n",
    "from src.xgboost_model import XGBoostModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de4c9805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataHandler initialized - Using 52 features - Test year: 2020\n"
     ]
    }
   ],
   "source": [
    "dh = DataHandler(test_year=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b114c8eb",
   "metadata": {},
   "source": [
    "### **Model 1: Standard XGBoost**\n",
    "Now, we will execute the full pipeline for a standard XGBoost model without using PCA.\n",
    "\n",
    "#### Initialize XGBoostModel Handler\n",
    "Here, we create an instance of the `XGBoostModel` class. We provide a unique `model_name` (`'xgb_base'`) which will be used to name all the output files (study, model, and predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42e1d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoostModel initialized with model name: xgb_base\n",
      "Optuna study will be stored in  : /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/optuna/xgb_base_study.pkl\n",
      "Trained model will be stored in : /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/models/xgb_base_model.json\n",
      "Final preds will be stored in   : /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/preds/xgb_base_preds.csv\n"
     ]
    }
   ],
   "source": [
    "xgb_base = XGBoostModel(dh, model_name='xgb_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4af3ab7",
   "metadata": {},
   "source": [
    "#### Run Optuna Hyperparameter Study\n",
    "This cell runs the Optuna hyperparameter search using the efficient ASHA pruner. It will perform 3-fold cross-validation on the training years to find the optimal set of hyperparameters that minimizes the custom weighted cross-entropy metric. The study object is saved upon completion.\n",
    "\n",
    "*   `n_trials`: The number of different hyperparameter combinations to test.\n",
    "*   `timeout`: A safety stop in minutes for the entire study.\n",
    "*   `min_resource`: The minimum number of boosting rounds a trial must train for before it can be pruned.\n",
    "*   `reduction_factor`: The factor by which resources are reduced in ASHA (e.g., halving the number of trials at each rung)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0a373d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-23 10:33:38,734] A new study created in memory with name: xgb_base_study\n",
      "[I 2025-10-23 10:33:40,436] Trial 6 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:40,490] Trial 4 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:40,496] Trial 1 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:40,691] Trial 7 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:40,811] Trial 5 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:40,920] Trial 2 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:40,948] Trial 3 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:41,306] Trial 9 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:41,725] Trial 10 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:42,194] Trial 13 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:42,276] Trial 14 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:42,387] Trial 16 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:42,885] Trial 12 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-10-23 10:33:42,899] Trial 17 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:43,000] Trial 8 finished with value: 1.006864 and parameters: {'learning_rate': 0.2964989620747212, 'gamma': 4.844160326154697, 'subsample': 0.9864026832022925, 'colsample_bytree': 0.6179409536946777, 'colsample_bylevel': 0.9188152011184119, 'colsample_bynode': 0.7784778347539822, 'reg_alpha': 0.0008223319444587041, 'reg_lambda': 0.00022268176630977027, 'max_depth': 4, 'min_child_weight': 8}. Best is trial 8 with value: 1.006864.\n",
      "[I 2025-10-23 10:33:43,076] Trial 18 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:44,047] Trial 15 pruned. Trial was pruned at iteration 32.\n",
      "[I 2025-10-23 10:33:44,605] Trial 20 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-10-23 10:33:44,738] Trial 0 finished with value: 0.9989736666666666 and parameters: {'learning_rate': 0.251774098125767, 'gamma': 0.5109953965070663, 'subsample': 0.759594307940735, 'colsample_bytree': 0.5330890740415979, 'colsample_bylevel': 0.8184407625874629, 'colsample_bynode': 0.684200870802032, 'reg_alpha': 0.0002615127949197172, 'reg_lambda': 0.006595819435765003, 'max_depth': 11, 'min_child_weight': 3}. Best is trial 0 with value: 0.9989736666666666.\n",
      "[I 2025-10-23 10:33:45,219] Trial 19 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-10-23 10:33:45,955] Trial 11 finished with value: 1.0014273333333332 and parameters: {'learning_rate': 0.1780819200499015, 'gamma': 1.3001020994212387, 'subsample': 0.7783036434893468, 'colsample_bytree': 0.5716429559789487, 'colsample_bylevel': 0.62209051722178, 'colsample_bynode': 0.4906175139535594, 'reg_alpha': 0.007489064945898559, 'reg_lambda': 0.00014312826903959569, 'max_depth': 10, 'min_child_weight': 9}. Best is trial 0 with value: 0.9989736666666666.\n",
      "[I 2025-10-23 10:33:46,165] Trial 27 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:46,201] Trial 22 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-10-23 10:33:47,071] Trial 28 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:47,222] Trial 21 finished with value: 1.0014663333333333 and parameters: {'learning_rate': 0.2982632737051757, 'gamma': 0.3508345479763806, 'subsample': 0.9992416684767901, 'colsample_bytree': 0.6931580959245457, 'colsample_bylevel': 0.9796593204799628, 'colsample_bynode': 0.7165857106701259, 'reg_alpha': 3.0125576531692473, 'reg_lambda': 6.619791576353489, 'max_depth': 5, 'min_child_weight': 15}. Best is trial 0 with value: 0.9989736666666666.\n",
      "[I 2025-10-23 10:33:47,303] Trial 24 finished with value: 1.000127 and parameters: {'learning_rate': 0.2934403521245177, 'gamma': 0.6410317604245268, 'subsample': 0.5971851755610856, 'colsample_bytree': 0.9981470739677178, 'colsample_bylevel': 0.9888529648764258, 'colsample_bynode': 0.7375146609916691, 'reg_alpha': 0.019934367128184673, 'reg_lambda': 0.0007772552576711902, 'max_depth': 5, 'min_child_weight': 7}. Best is trial 0 with value: 0.9989736666666666.\n",
      "[I 2025-10-23 10:33:47,500] Trial 29 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:48,030] Trial 31 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:48,360] Trial 32 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:49,174] Trial 33 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:49,309] Trial 34 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:49,500] Trial 35 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:49,598] Trial 30 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-10-23 10:33:51,091] Trial 38 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-10-23 10:33:52,066] Trial 36 pruned. Trial was pruned at iteration 32.\n",
      "[I 2025-10-23 10:33:52,231] Trial 37 pruned. Trial was pruned at iteration 32.\n",
      "[I 2025-10-23 10:33:53,463] Trial 39 pruned. Trial was pruned at iteration 32.\n",
      "[I 2025-10-23 10:33:54,766] Trial 45 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-10-23 10:33:55,206] Trial 26 finished with value: 0.9977116666666667 and parameters: {'learning_rate': 0.29582773544059665, 'gamma': 0.24282726346185357, 'subsample': 0.7435265594179045, 'colsample_bytree': 0.7094930664550283, 'colsample_bylevel': 0.9627040471498327, 'colsample_bynode': 0.7429854564014015, 'reg_alpha': 0.08342268113790362, 'reg_lambda': 0.00020582747789126137, 'max_depth': 3, 'min_child_weight': 6}. Best is trial 26 with value: 0.9977116666666667.\n",
      "[I 2025-10-23 10:33:55,765] Trial 46 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-10-23 10:33:55,845] Trial 40 finished with value: 0.9982196666666666 and parameters: {'learning_rate': 0.1971681354882083, 'gamma': 0.35420441893149734, 'subsample': 0.7798511156981008, 'colsample_bytree': 0.9025006971852458, 'colsample_bylevel': 0.6157034107958143, 'colsample_bynode': 0.68243873031447, 'reg_alpha': 0.143581616380431, 'reg_lambda': 0.0018956819815481745, 'max_depth': 5, 'min_child_weight': 2}. Best is trial 26 with value: 0.9977116666666667.\n",
      "[I 2025-10-23 10:33:56,287] Trial 41 finished with value: 0.9992233333333335 and parameters: {'learning_rate': 0.21222349550345215, 'gamma': 0.41887005911135555, 'subsample': 0.9397942376949067, 'colsample_bytree': 0.5507184231327753, 'colsample_bylevel': 0.6031117033451249, 'colsample_bynode': 0.5941899627706525, 'reg_alpha': 0.3250339858928818, 'reg_lambda': 0.033753942991315046, 'max_depth': 5, 'min_child_weight': 3}. Best is trial 26 with value: 0.9977116666666667.\n",
      "[I 2025-10-23 10:33:56,336] Trial 42 finished with value: 0.9988466666666667 and parameters: {'learning_rate': 0.20148896110730122, 'gamma': 0.3993312125706888, 'subsample': 0.7921961235413912, 'colsample_bytree': 0.5427998777844931, 'colsample_bylevel': 0.6299559217256441, 'colsample_bynode': 0.6638665816436937, 'reg_alpha': 0.15306410298842898, 'reg_lambda': 0.0233836131104602, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 26 with value: 0.9977116666666667.\n",
      "[I 2025-10-23 10:33:56,399] Trial 48 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:56,899] Trial 47 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:57,172] Trial 23 finished with value: 0.9967753333333333 and parameters: {'learning_rate': 0.2996541219076564, 'gamma': 0.07507967748953392, 'subsample': 0.7502119757458177, 'colsample_bytree': 0.6731920618621817, 'colsample_bylevel': 0.999464815998002, 'colsample_bynode': 0.9744811880425495, 'reg_alpha': 0.04492399658099902, 'reg_lambda': 6.1423075950339685, 'max_depth': 6, 'min_child_weight': 15}. Best is trial 23 with value: 0.9967753333333333.\n",
      "[I 2025-10-23 10:33:57,398] Trial 44 pruned. Trial was pruned at iteration 32.\n",
      "[I 2025-10-23 10:33:57,416] Trial 49 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:58,013] Trial 52 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:58,111] Trial 53 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:58,167] Trial 43 finished with value: 0.9990399999999999 and parameters: {'learning_rate': 0.18608442938790623, 'gamma': 0.31267819748981385, 'subsample': 0.8447337451316795, 'colsample_bytree': 0.5445029061441535, 'colsample_bylevel': 0.6356569065862191, 'colsample_bynode': 0.6843340142940131, 'reg_alpha': 0.37787633840810636, 'reg_lambda': 0.0020735697991902157, 'max_depth': 5, 'min_child_weight': 12}. Best is trial 23 with value: 0.9967753333333333.\n",
      "[I 2025-10-23 10:33:58,580] Trial 54 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:58,634] Trial 56 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:58,795] Trial 55 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:33:59,876] Trial 59 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-10-23 10:34:00,549] Trial 61 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-10-23 10:34:00,665] Trial 62 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-10-23 10:34:00,868] Trial 63 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-10-23 10:34:03,003] Trial 50 pruned. Trial was pruned at iteration 64.\n",
      "[I 2025-10-23 10:34:03,570] Trial 64 pruned. Trial was pruned at iteration 32.\n",
      "[I 2025-10-23 10:34:03,632] Trial 51 finished with value: 0.9980946666666668 and parameters: {'learning_rate': 0.15613739192475504, 'gamma': 0.3380392802313524, 'subsample': 0.9656095204608008, 'colsample_bytree': 0.8801915397551301, 'colsample_bylevel': 0.6490418055536045, 'colsample_bynode': 0.7679445514915167, 'reg_alpha': 0.1907523212366537, 'reg_lambda': 0.07304159890986657, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 23 with value: 0.9967753333333333.\n",
      "[I 2025-10-23 10:34:04,788] Trial 65 pruned. Trial was pruned at iteration 32.\n",
      "[I 2025-10-23 10:34:04,918] Trial 66 pruned. Trial was pruned at iteration 32.\n",
      "[I 2025-10-23 10:34:04,975] Trial 67 pruned. Trial was pruned at iteration 32.\n",
      "[I 2025-10-23 10:34:05,995] Trial 69 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:34:06,203] Trial 60 pruned. Trial was pruned at iteration 64.\n",
      "[I 2025-10-23 10:34:06,247] Trial 70 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:34:06,288] Trial 58 pruned. Trial was pruned at iteration 64.\n",
      "[I 2025-10-23 10:34:06,876] Trial 73 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:34:07,114] Trial 71 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:34:07,860] Trial 76 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:34:07,904] Trial 68 pruned. Trial was pruned at iteration 32.\n",
      "[I 2025-10-23 10:34:07,972] Trial 75 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:34:08,356] Trial 77 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:34:09,002] Trial 79 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:34:09,819] Trial 80 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:34:09,936] Trial 78 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-10-23 10:34:10,116] Trial 25 finished with value: 0.9946693333333334 and parameters: {'learning_rate': 0.290731718809791, 'gamma': 0.005917558995819139, 'subsample': 0.7197902893699779, 'colsample_bytree': 0.722251835097874, 'colsample_bylevel': 0.9765214622058169, 'colsample_bynode': 0.7398911841006237, 'reg_alpha': 0.01176549409641306, 'reg_lambda': 0.0015235803350705456, 'max_depth': 3, 'min_child_weight': 7}. Best is trial 25 with value: 0.9946693333333334.\n",
      "[I 2025-10-23 10:34:10,831] Trial 81 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-10-23 10:34:11,465] Trial 83 pruned. Trial was pruned at iteration 16.\n",
      "[I 2025-10-23 10:34:14,027] Trial 57 finished with value: 0.9946083333333334 and parameters: {'learning_rate': 0.24193054395455338, 'gamma': 0.032754483393073075, 'subsample': 0.8251262031577257, 'colsample_bytree': 0.7695334455198166, 'colsample_bylevel': 0.6518753333600602, 'colsample_bynode': 0.6182478774533648, 'reg_alpha': 0.0004328051895913176, 'reg_lambda': 0.819443394873088, 'max_depth': 4, 'min_child_weight': 1}. Best is trial 57 with value: 0.9946083333333334.\n",
      "[I 2025-10-23 10:34:14,537] Trial 86 pruned. Trial was pruned at iteration 32.\n",
      "[I 2025-10-23 10:34:14,926] Trial 85 pruned. Trial was pruned at iteration 32.\n",
      "[I 2025-10-23 10:34:15,923] Trial 84 finished with value: 0.9985836666666668 and parameters: {'learning_rate': 0.2089002808015016, 'gamma': 0.4299878157469329, 'subsample': 0.972818689728278, 'colsample_bytree': 0.5673851440455981, 'colsample_bylevel': 0.6126017557540213, 'colsample_bynode': 0.5169584845181663, 'reg_alpha': 0.04140032361360517, 'reg_lambda': 0.00035554708742567467, 'max_depth': 5, 'min_child_weight': 3}. Best is trial 57 with value: 0.9946083333333334.\n",
      "[I 2025-10-23 10:34:16,045] Trial 82 pruned. Trial was pruned at iteration 64.\n",
      "[I 2025-10-23 10:34:18,136] Trial 72 finished with value: 0.9972293333333333 and parameters: {'learning_rate': 0.17605780670658083, 'gamma': 0.19645100487736433, 'subsample': 0.6899680370440302, 'colsample_bytree': 0.8817244222607994, 'colsample_bylevel': 0.5676049753997549, 'colsample_bynode': 0.7499310538084196, 'reg_alpha': 0.073245809876224, 'reg_lambda': 0.0009223539159320194, 'max_depth': 6, 'min_child_weight': 4}. Best is trial 57 with value: 0.9946083333333334.\n",
      "[I 2025-10-23 10:34:21,482] Trial 74 pruned. Trial was pruned at iteration 128.\n",
      "[I 2025-10-23 10:34:23,510] Trial 96 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:34:24,650] Trial 89 finished with value: 0.9966506666666666 and parameters: {'learning_rate': 0.2855115437304844, 'gamma': 0.08012221779534923, 'subsample': 0.7997959331356382, 'colsample_bytree': 0.7361515091648462, 'colsample_bylevel': 0.8653872644009071, 'colsample_bynode': 0.9402321301705769, 'reg_alpha': 0.030831467380085607, 'reg_lambda': 0.0007083980052819093, 'max_depth': 11, 'min_child_weight': 11}. Best is trial 57 with value: 0.9946083333333334.\n",
      "[I 2025-10-23 10:34:24,905] Trial 97 pruned. Trial was pruned at iteration 8.\n",
      "[I 2025-10-23 10:34:29,870] Trial 93 pruned. Trial was pruned at iteration 128.\n",
      "[I 2025-10-23 10:34:30,735] Trial 94 pruned. Trial was pruned at iteration 128.\n",
      "[I 2025-10-23 10:34:33,026] Trial 95 finished with value: 0.9949926666666666 and parameters: {'learning_rate': 0.2860921670357489, 'gamma': 0.044588288067109016, 'subsample': 0.9749273716530991, 'colsample_bytree': 0.7370640216705238, 'colsample_bylevel': 0.9230031823928606, 'colsample_bynode': 0.7416777644466235, 'reg_alpha': 0.030881245837697566, 'reg_lambda': 3.6632274192477924e-05, 'max_depth': 3, 'min_child_weight': 5}. Best is trial 57 with value: 0.9946083333333334.\n",
      "[I 2025-10-23 10:34:33,108] Trial 90 pruned. Trial was pruned at iteration 128.\n",
      "[I 2025-10-23 10:34:34,005] Trial 88 finished with value: 0.9949490000000001 and parameters: {'learning_rate': 0.2862382667086935, 'gamma': 0.006323180368355552, 'subsample': 0.7313975819969527, 'colsample_bytree': 0.7232149481521162, 'colsample_bylevel': 0.925805434905878, 'colsample_bynode': 0.9209071702892392, 'reg_alpha': 0.03014912739198073, 'reg_lambda': 0.000410910205517163, 'max_depth': 3, 'min_child_weight': 11}. Best is trial 57 with value: 0.9946083333333334.\n",
      "[I 2025-10-23 10:34:34,669] Trial 92 finished with value: 0.9951096666666667 and parameters: {'learning_rate': 0.2764325457180317, 'gamma': 0.018082801567456563, 'subsample': 0.8035795443254681, 'colsample_bytree': 0.7309653185744256, 'colsample_bylevel': 0.9178390729228298, 'colsample_bynode': 0.7413054040836178, 'reg_alpha': 1.2962536124206824e-07, 'reg_lambda': 5.1407490997754905, 'max_depth': 3, 'min_child_weight': 11}. Best is trial 57 with value: 0.9946083333333334.\n",
      "[I 2025-10-23 10:34:34,991] Trial 91 finished with value: 0.99512 and parameters: {'learning_rate': 0.2812218273898608, 'gamma': 7.095657917816078e-06, 'subsample': 0.8429531514117419, 'colsample_bytree': 0.7432760346490732, 'colsample_bylevel': 0.6270219216881996, 'colsample_bynode': 0.6366141378696528, 'reg_alpha': 0.03151378852303193, 'reg_lambda': 0.07767107523224272, 'max_depth': 3, 'min_child_weight': 11}. Best is trial 57 with value: 0.9946083333333334.\n",
      "[I 2025-10-23 10:34:34,995] Trial 87 finished with value: 0.9942566666666667 and parameters: {'learning_rate': 0.20934415984202634, 'gamma': 0.01248134336564366, 'subsample': 0.7322252935015268, 'colsample_bytree': 0.7372352102775366, 'colsample_bylevel': 0.9759430519429679, 'colsample_bynode': 0.7214443735212577, 'reg_alpha': 0.4508419359396373, 'reg_lambda': 0.00043211407266855763, 'max_depth': 11, 'min_child_weight': 5}. Best is trial 87 with value: 0.9942566666666667.\n",
      "[I 2025-10-23 10:34:35,748] Trial 98 finished with value: 0.9948716666666666 and parameters: {'learning_rate': 0.27979341648000766, 'gamma': 0.022023563647879496, 'subsample': 0.9758100285141483, 'colsample_bytree': 0.7239577632651707, 'colsample_bylevel': 0.925348149593271, 'colsample_bynode': 0.9563390910837277, 'reg_alpha': 0.007486540561596889, 'reg_lambda': 8.945724680484103, 'max_depth': 7, 'min_child_weight': 6}. Best is trial 87 with value: 0.9942566666666667.\n",
      "[I 2025-10-23 10:34:36,374] Trial 99 finished with value: 0.9944706666666666 and parameters: {'learning_rate': 0.2780488911005036, 'gamma': 0.003973270489862568, 'subsample': 0.7015056894624285, 'colsample_bytree': 0.8991928160295498, 'colsample_bylevel': 0.47097158244309634, 'colsample_bynode': 0.9610680887108839, 'reg_alpha': 2.3419145085410776e-07, 'reg_lambda': 3.160835922564584e-05, 'max_depth': 7, 'min_child_weight': 6}. Best is trial 87 with value: 0.9942566666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Study concluded. Results:\n",
      "Best trial: 87\n",
      "Best loss: 0.9942566666666667\n",
      "Best params: {'learning_rate': 0.20934415984202634, 'gamma': 0.01248134336564366, 'subsample': 0.7322252935015268, 'colsample_bytree': 0.7372352102775366, 'colsample_bylevel': 0.9759430519429679, 'colsample_bynode': 0.7214443735212577, 'reg_alpha': 0.4508419359396373, 'reg_lambda': 0.00043211407266855763, 'max_depth': 11, 'min_child_weight': 5}\n",
      "Optimal boosting rounds: 107\n",
      "Study saved to /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/optuna/xgb_base_study.pkl\n"
     ]
    }
   ],
   "source": [
    "xgb_base.run_optuna_study(\n",
    "    n_trials=100,\n",
    "    timeout=10,\n",
    "    min_resource=8,  \n",
    "    reduction_factor=2,  \n",
    "    use_pca=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2ad97d",
   "metadata": {},
   "source": [
    "#### Train Final Model\n",
    "Using the best hyperparameters and the optimal number of boosting rounds found by Optuna, this cell trains the final XGBoost model on the entire training dataset (2008, 2012, and 2016 combined). The trained model is saved to the results directory in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f392797f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training xgb_base for 107 boosting rounds...\n",
      "Using best params: {'learning_rate': 0.20934415984202634, 'gamma': 0.01248134336564366, 'subsample': 0.7322252935015268, 'colsample_bytree': 0.7372352102775366, 'colsample_bylevel': 0.9759430519429679, 'colsample_bynode': 0.7214443735212577, 'reg_alpha': 0.4508419359396373, 'reg_lambda': 0.00043211407266855763, 'max_depth': 11, 'min_child_weight': 5}\n",
      "Training completed in 0.49 seconds.\n",
      "Model saved to /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/models/xgb_base_model.json\n"
     ]
    }
   ],
   "source": [
    "xgb_base.train_final_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9582d7",
   "metadata": {},
   "source": [
    "#### Generate Final Predictions\n",
    "Finally, we load the trained model and use it to make predictions on the held-out 2020 test set. The predictions are saved to a CSV file in the results directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de32f05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_base predictions saved to: /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/preds/xgb_base_preds.csv.\n",
      "\n",
      "Base XGBoost Model Predictions (first 5 rows):\n",
      "[[0.13650045 0.29802307 0.02114831 0.5443282 ]\n",
      " [0.12210447 0.33626625 0.02544304 0.5161862 ]\n",
      " [0.16061217 0.17182407 0.0100354  0.65752834]\n",
      " [0.09442554 0.27459973 0.01240689 0.6185678 ]\n",
      " [0.08282262 0.31229147 0.02329286 0.5815931 ]]\n"
     ]
    }
   ],
   "source": [
    "preds_base = xgb_base.make_final_predictions()\n",
    "print(\"\\nBase XGBoost Model Predictions (first 5 rows):\")\n",
    "print(preds_base[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math392",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
