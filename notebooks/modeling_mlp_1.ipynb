{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80cfbb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device (Apple Silicon GPU)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the absolute path of the current notebook\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Get the project root directory (which is the parent of the 'notebooks' directory)\n",
    "project_root = notebook_path.parent\n",
    "\n",
    "# Add BOTH the project root and the src directory to the Python path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "if str(project_root / 'src') not in sys.path:\n",
    "    sys.path.append(str(project_root / 'src'))\n",
    "\n",
    "# Now, we can import our modules\n",
    "from src.data_handling import DataHandler\n",
    "from src.mlp_model import MLPModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fe1b7f",
   "metadata": {},
   "source": [
    "#### Initialize DataHandler\n",
    "This cell creates an instance of the `DataHandler` class. It will load the dataset, define the feature/target sets, and pre-fit the necessary data processing objects. The test year is set to 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0db5ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataHandler initialized - Using 52 features - Test year: 2020\n"
     ]
    }
   ],
   "source": [
    "dh = DataHandler(test_year=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb35ed",
   "metadata": {},
   "source": [
    "### **Model: MLP with 1 Hidden Layer**\n",
    "\n",
    "#### Initialize MLPModel Handler\n",
    "Here, we create an instance of the `MLPModel` class, explicitly setting `depth=2`. The `model_name` ensures all artifacts for this architecture are saved to unique files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfa76816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPModel initialized with model name mlp_depth1 and depth 1.\n",
      "Optuna study will be stored in  : /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/optuna/mlp_depth1_study.pkl\n",
      "Trained model will be stored in : /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/models/mlp_depth1_model.pth\n",
      "Final preds will be stored in   : /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/preds/mlp_depth1_preds.csv\n"
     ]
    }
   ],
   "source": [
    "mlp_depth1 = MLPModel(dh, model_name='mlp_depth1', depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e2b3c8",
   "metadata": {},
   "source": [
    "#### Run Optuna Hyperparameter Study (Depth=2)\n",
    "This cell runs the Optuna study. For this specific 2-layer architecture, it will find the optimal learning rate, weight decay, batch size, and the number of neurons and dropout rates for both hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2610909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-23 10:45:58,807] A new study created in memory with name: mlp_depth1_study\n",
      "[I 2025-10-23 10:46:19,248] Trial 2 pruned. \n",
      "[I 2025-10-23 10:46:19,601] Trial 4 pruned. \n",
      "[I 2025-10-23 10:46:19,986] Trial 6 pruned. \n",
      "[I 2025-10-23 10:46:21,286] Trial 8 pruned. \n",
      "[I 2025-10-23 10:46:29,581] Trial 3 pruned. \n",
      "[I 2025-10-23 10:46:36,841] Trial 12 pruned. \n",
      "[I 2025-10-23 10:46:37,939] Trial 9 pruned. \n",
      "[I 2025-10-23 10:46:39,964] Trial 10 pruned. \n",
      "[I 2025-10-23 10:46:40,791] Trial 11 pruned. \n",
      "[I 2025-10-23 10:46:51,025] Trial 18 pruned. \n",
      "[I 2025-10-23 10:46:51,216] Trial 13 pruned. \n",
      "[I 2025-10-23 10:46:53,507] Trial 16 pruned. \n",
      "[I 2025-10-23 10:46:58,042] Trial 14 pruned. \n",
      "[I 2025-10-23 10:47:01,666] Trial 15 pruned. \n",
      "[I 2025-10-23 10:47:04,652] Trial 20 pruned. \n",
      "[I 2025-10-23 10:47:06,876] Trial 21 pruned. \n",
      "[I 2025-10-23 10:47:17,452] Trial 22 pruned. \n",
      "[I 2025-10-23 10:47:24,865] Trial 24 pruned. \n",
      "[I 2025-10-23 10:47:27,026] Trial 25 pruned. \n",
      "[I 2025-10-23 10:47:34,735] Trial 23 pruned. \n",
      "[I 2025-10-23 10:47:45,759] Trial 19 pruned. \n",
      "[I 2025-10-23 10:47:53,606] Trial 26 pruned. \n",
      "[I 2025-10-23 10:47:56,662] Trial 5 pruned. \n",
      "[I 2025-10-23 10:48:16,758] Trial 32 pruned. \n",
      "[I 2025-10-23 10:48:19,311] Trial 0 finished with value: 1.0165495773156483 and parameters: {'learning_rate': 0.00023895540300422586, 'weight_decay': 3.8809281294361685e-05, 'batch_size': 128, 'n_hidden_1': 56, 'dropout_rate_1': 0.4871622236380969}. Best is trial 0 with value: 1.0165495773156483.\n",
      "[I 2025-10-23 10:48:20,968] Trial 1 finished with value: 1.0027600079774857 and parameters: {'learning_rate': 0.014248873068070657, 'weight_decay': 8.37271378812079e-06, 'batch_size': 192, 'n_hidden_1': 104, 'dropout_rate_1': 0.12326572405930586}. Best is trial 1 with value: 1.0027600079774857.\n",
      "[I 2025-10-23 10:48:27,320] Trial 31 pruned. \n",
      "[I 2025-10-23 10:48:28,297] Trial 28 pruned. \n",
      "[I 2025-10-23 10:48:33,860] Trial 7 finished with value: 1.0037269840637844 and parameters: {'learning_rate': 0.016767490513551104, 'weight_decay': 1.6461327190957627e-05, 'batch_size': 192, 'n_hidden_1': 120, 'dropout_rate_1': 0.3495329382236743}. Best is trial 1 with value: 1.0027600079774857.\n",
      "[I 2025-10-23 10:48:35,676] Trial 33 pruned. \n",
      "[I 2025-10-23 10:48:38,539] Trial 34 pruned. \n",
      "[I 2025-10-23 10:48:41,321] Trial 35 pruned. \n",
      "[I 2025-10-23 10:48:47,014] Trial 36 pruned. \n",
      "[I 2025-10-23 10:48:47,359] Trial 37 pruned. \n",
      "[I 2025-10-23 10:48:50,292] Trial 17 finished with value: 1.0029061883687973 and parameters: {'learning_rate': 0.010233924451553232, 'weight_decay': 2.139525186104163e-05, 'batch_size': 192, 'n_hidden_1': 56, 'dropout_rate_1': 0.4351020526840375}. Best is trial 1 with value: 1.0027600079774857.\n",
      "[I 2025-10-23 10:48:51,442] Trial 39 pruned. \n",
      "[I 2025-10-23 10:48:55,227] Trial 38 pruned. \n",
      "[I 2025-10-23 10:49:12,480] Trial 40 pruned. \n",
      "[I 2025-10-23 10:49:19,475] Trial 44 pruned. \n",
      "[I 2025-10-23 10:49:20,235] Trial 41 pruned. \n",
      "[I 2025-10-23 10:49:21,757] Trial 45 pruned. \n",
      "[I 2025-10-23 10:49:30,629] Trial 46 pruned. \n",
      "[I 2025-10-23 10:49:41,439] Trial 27 finished with value: 1.0028783331314723 and parameters: {'learning_rate': 0.018844723422192716, 'weight_decay': 0.0009558605800384265, 'batch_size': 192, 'n_hidden_1': 56, 'dropout_rate_1': 0.11130645831866232}. Best is trial 1 with value: 1.0027600079774857.\n",
      "[I 2025-10-23 10:49:43,030] Trial 29 finished with value: 1.0041731148958206 and parameters: {'learning_rate': 0.02027317736685163, 'weight_decay': 8.011267125218243e-05, 'batch_size': 192, 'n_hidden_1': 56, 'dropout_rate_1': 0.4956243367918945}. Best is trial 1 with value: 1.0027600079774857.\n",
      "[I 2025-10-23 10:49:47,109] Trial 47 pruned. \n",
      "[I 2025-10-23 10:49:48,203] Trial 30 finished with value: 1.003204549352328 and parameters: {'learning_rate': 0.019604804491860996, 'weight_decay': 7.77074729567701e-05, 'batch_size': 192, 'n_hidden_1': 24, 'dropout_rate_1': 0.3892617927053931}. Best is trial 1 with value: 1.0027600079774857.\n",
      "[I 2025-10-23 10:49:49,251] Trial 48 pruned. \n",
      "[I 2025-10-23 10:49:56,635] Trial 43 finished with value: 1.0018598139286041 and parameters: {'learning_rate': 0.009786650779821545, 'weight_decay': 0.00996677178234352, 'batch_size': 192, 'n_hidden_1': 104, 'dropout_rate_1': 0.1709029094387794}. Best is trial 43 with value: 1.0018598139286041.\n",
      "[I 2025-10-23 10:49:57,813] Trial 42 finished with value: 1.0016956478357315 and parameters: {'learning_rate': 0.01040797308412417, 'weight_decay': 1.4122812944257067e-05, 'batch_size': 192, 'n_hidden_1': 128, 'dropout_rate_1': 0.16420066820839307}. Best is trial 42 with value: 1.0016956478357315.\n",
      "[I 2025-10-23 10:49:59,778] Trial 49 finished with value: 1.0036207536856334 and parameters: {'learning_rate': 0.00986863726218594, 'weight_decay': 0.00017304122283908795, 'batch_size': 192, 'n_hidden_1': 112, 'dropout_rate_1': 0.42445898414423044}. Best is trial 42 with value: 1.0016956478357315.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Study concluded and saved to /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/optuna/mlp_depth1_study.pkl.\n",
      "Best trial: 42\n",
      "Best loss: 1.0016956478357315\n",
      "Best params: {'learning_rate': 0.01040797308412417, 'weight_decay': 1.4122812944257067e-05, 'batch_size': 192, 'n_hidden_1': 128, 'dropout_rate_1': 0.16420066820839307}\n",
      "Best epoch: 40\n"
     ]
    }
   ],
   "source": [
    "mlp_depth1.run_optuna_study(\n",
    "    n_trials=50,\n",
    "    timeout=30,               # Stop study after 30 minutes\n",
    "    max_epochs=40,            # Max epochs to train each trial\n",
    "    min_resource=4,          # Min epochs before pruning\n",
    "    reduction_factor=2,\n",
    "    use_pca=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b08b7c",
   "metadata": {},
   "source": [
    "#### Train Final Model (Depth=1)\n",
    "Using the best hyperparameters and the optimal number of training epochs found by Optuna, this cell trains the final 2-layer MLP on the entire training dataset. The model's weights (`.pth` file) are saved to the results directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "069ee3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mlp_depth1 with depth 1 for 40 epochs with patience of 10 epochs.\n",
      "Using batch size: 192 and best params: {'learning_rate': 0.01040797308412417, 'weight_decay': 1.4122812944257067e-05, 'batch_size': 192, 'n_hidden_1': 128, 'dropout_rate_1': 0.16420066820839307}.\n",
      "Epoch    0, Loss: 1.039254\n",
      "Epoch    1, Loss: 1.000370\n",
      "Epoch    2, Loss: 0.998688\n",
      "Epoch    3, Loss: 0.998679\n",
      "Epoch    4, Loss: 0.994686\n",
      "Epoch    5, Loss: 0.993515\n",
      "Epoch    6, Loss: 0.994243\n",
      "Epoch    7, Loss: 0.996671\n",
      "Epoch    8, Loss: 0.994295\n",
      "Epoch    9, Loss: 0.994711\n",
      "Epoch   10, Loss: 0.994124\n",
      "Epoch   11, Loss: 0.993570\n",
      "Epoch   12, Loss: 0.994356\n",
      "Epoch   13, Loss: 0.994356\n",
      "Epoch   14, Loss: 0.994505\n",
      "Epoch   15, Loss: 0.993507\n",
      "Epoch   16, Loss: 0.993540\n",
      "Epoch   17, Loss: 0.991932\n",
      "Epoch   18, Loss: 0.993162\n",
      "Epoch   19, Loss: 0.992082\n",
      "Epoch   20, Loss: 0.993136\n",
      "Epoch   21, Loss: 0.993292\n",
      "Epoch   22, Loss: 0.994159\n",
      "Epoch   23, Loss: 0.993268\n",
      "Epoch   24, Loss: 0.995443\n",
      "Epoch   25, Loss: 0.994729\n",
      "Epoch   26, Loss: 0.994273\n",
      "Epoch   27, Loss: 0.992597\n",
      "Early stopping at epoch 27.\n",
      "Training completed in 4.86 seconds.\n",
      "Model saved to /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/models/mlp_depth1_model.pth\n"
     ]
    }
   ],
   "source": [
    "mlp_depth1.train_final_model(patience=10) # Stop if loss doesn't improve for 10 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2443ab8",
   "metadata": {},
   "source": [
    "#### Generate Final Predictions (Depth=1)\n",
    "Finally, we load the trained 2-layer model and use it to make predictions on the held-out 2020 test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03b7bd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_depth1 predictions saved to: /Users/arvindsuresh/Documents/Github/Election-prediction-May-2025/2020-results-20251023/preds/mlp_depth1_preds.csv.\n",
      "\n",
      "MLP (Depth=1) Predictions (first 5 rows):\n",
      "[[0.154508   0.29219887 0.02766594 0.5256272 ]\n",
      " [0.14840181 0.29685402 0.03713985 0.5176043 ]\n",
      " [0.19731696 0.16657394 0.00948197 0.62662715]\n",
      " [0.12144238 0.2577286  0.01204269 0.60878634]\n",
      " [0.09964711 0.3096592  0.01723056 0.57346314]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the 2020 test data\n",
    "preds_depth1 = mlp_depth1.make_final_predictions()\n",
    "print(\"\\nMLP (Depth=1) Predictions (first 5 rows):\")\n",
    "print(preds_depth1[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math392",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
